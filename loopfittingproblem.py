# -*- coding: utf-8 -*-
"""LoopFittingProblem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wSZsar0cj50tGo5IeilwFS4gMP2vm6uc

# Hystersis Loop Dataset - AFM

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pycroscopy/DTMicroscope/blob/main/notebooks/Static%20Problems/LoopFittingProblem.ipynb)

 This dataset is a 50x50 hysteresis loop dataset on a PbTiO3 thin film, acquired by piezoresponse force spectroscopy. You can use this to test different fitting algorithms. The X,Y scale on the images is 2um

by R. Vasudevan (CNMS/ORNL)
"""

import matplotlib.pyplot as plt
import numpy as np
from scipy.special import erf

hysteresis_loops = np.load('hysteresis_loops.npy')
dc_vec = np.load('dc_vec.npy')

"""# Plot some random loops"""

if hysteresis_loops.ndim == 3:
    loops_flat = hysteresis_loops.reshape(-1, hysteresis_loops.shape[-1])
else:
    loops_flat = hysteresis_loops

num_loops_to_plot = 25
# Randomly select 25 indices for the hysteresis loops to plot
random_indices = np.random.choice(loops_flat.shape[0], num_loops_to_plot, replace=False)

# Create a 5x5 grid of subplots
fig, axes = plt.subplots(5, 5, figsize=(15, 15))
axes = axes.flatten() # Flatten the 5x5 array of axes for easier iteration

# Plot each random hysteresis loop in a separate subplot
for i, ax in enumerate(axes):
    loop_index = random_indices[i]
    loop_data = loops_flat[loop_index]

    ax.plot(dc_vec, loop_data)
    ax.set_title(f'Loop {loop_index}')
    ax.set_xlabel('Voltage (V)')
    ax.set_ylabel('Response')
    ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout() # Adjust subplot parameters for a tight layout
plt.show()

# The loop fit function is defined in the cell below.
#This is the fit function for the loop - be careful with the DC vector!

"""## The loop fit function is defined in the cell below.
## This is the fit function for the loop - be careful with the DC vector!
"""

def loop_fit_function(vdc, coef_vec):
    """
    9 parameter fit function

    Parameters
    -----------
    vdc : 1D numpy array or list
        DC voltages
    coef_vec : 1D numpy array or list
        9 parameter coefficient vector

    Returns
    ---------
    loop_eval : 1D numpy array
        Loop values
    """

    a = coef_vec[:5]
    b = coef_vec[5:]
    d = 1000

    v1 = np.asarray(vdc[:int(len(vdc) / 2)])
    v2 = np.asarray(vdc[int(len(vdc) / 2):])

    g1 = (b[1] - b[0]) / 2 * (erf((v1 - a[2]) * d) + 1) + b[0]
    g2 = (b[3] - b[2]) / 2 * (erf((v2 - a[3]) * d) + 1) + b[2]

    y1 = (g1 * erf((v1 - a[2]) / g1) + b[0]) / (b[0] + b[1])
    y2 = (g2 * erf((v2 - a[3]) / g2) + b[2]) / (b[2] + b[3])

    f1 = a[0] + a[1] * y1 + a[4] * v1
    f2 = a[0] + a[1] * y2 + a[4] * v2

    loop_eval = np.hstack((f1, f2))
    return loop_eval

#Using this loop fit function, fit the projected loop (the third panel in the previous figure).
#You will need to be careful about the way the x vector is passed it needs to be 'rolled'
#I.e., Vdc needs to be increasing on one branch and decreasing on another, and split in the middle.

"""# Preprocessing

There are some loops that contain spikes. We attempt to fix it with simple linear interpolation.

Also roll vdc to be increasing on first branch and decreasing on another

## Cleaning
"""

import numpy as np


def clean_by_large_diff(v, y, diff_thresh=None, k_mad=8.0, expand=1):
    """
    Flag points around unusually large |dy| jumps, then linearly interpolate them.

    Parameters
    ----------
    v : 1D array
        Voltage (only used for interpolation x-axis; can be non-monotonic).
    y : 1D array
        Response.
    diff_thresh : float or None
        Absolute threshold on |diff(y)| to flag anomalies.
        If None, uses a robust threshold = median(|dy|) + k_mad * MAD(|dy|).
    k_mad : float
        Strength of robust threshold when diff_thresh=None.
    expand : int
        Also flag +/- expand neighboring points around each jump.

    Returns
    -------
    y_clean : 1D array, same shape as y
    mask    : boolean mask of replaced points (True = interpolated)
    """
    v = np.asarray(v, float)
    y = np.asarray(y, float)
    n = len(y)
    if n < 3:
        return y.copy(), np.zeros(n, dtype=bool)

    dy = np.diff(y)
    ady = np.abs(dy)

    if diff_thresh is None:
        med = np.median(ady)
        mad = np.median(np.abs(ady - med)) + 1e-12
        diff_thresh = med + k_mad * (1.4826 * mad)

    jumps = ady > diff_thresh  # length n-1

    mask = np.zeros(n, dtype=bool)
    idx = np.where(jumps)[0]
    if idx.size > 0:
        # flag both sides of each jump
        mask[idx] = True
        mask[idx + 1] = True

        # expand to neighbors if requested
        if expand > 0:
            base = np.where(mask)[0]
            for d in range(1, expand + 1):
                mask[np.clip(base - d, 0, n - 1)] = True
                mask[np.clip(base + d, 0, n - 1)] = True

    # interpolate over flagged points
    y_clean = y.copy()
    good = ~mask
    if good.sum() >= 2 and mask.any():
        # interpolate in index-space (most robust for non-monotonic v)
        x = np.arange(n)
        y_clean[mask] = np.interp(x[mask], x[good], y[good])

    return y_clean

from tqdm import tqdm

# index of minimum (−8.5 V)
imin = np.argmin(dc_vec)
# roll so that −8.5 V is at position 0
vdc_rolled = np.roll(dc_vec, -imin)
cleaned_loops = []
for y in tqdm(loops_flat):
  y_rolled = np.roll(y, -imin)
  q10 = np.quantile(y_rolled, 0.10)
  q90 = np.quantile(y_rolled, 0.90)
  spread = q90 - q10
  y_clean = clean_by_large_diff(vdc_rolled, y_rolled, diff_thresh=spread, expand=1)
  cleaned_loops.append(y_clean)

cleaned_loops = np.array(cleaned_loops)
print(cleaned_loops.shape)

"""## Examples

Note that the axes are not the same. This is for illustrative purpose that these spikes are significant deviation from the expected hysteresis loop.
"""

import numpy as np

id = 1240

y = loops_flat[id]
y_rolled = np.roll(y, -imin)

y_clean = cleaned_loops[id]

fig, ax = plt.subplots(ncols=2, figsize=(6,6))

ax[1].plot(vdc_rolled, y_rolled, label = 'raw')
ax[1].plot(vdc_rolled, y_clean, label = 'preprocessed')
ax[1].set_xlabel("Voltage (V)")
ax[1].set_ylabel("Response")
ax[1].set_title("Comparison")
ax[1].grid(True)
ax[1].set_ylim(-0.00009, 0.00007)

ax[0].plot(vdc_rolled, y_rolled)
ax[0].set_xlabel("Voltage (V)")
ax[0].set_ylabel("Response")
ax[0].set_title("Original shape")
ax[0].grid(True)

plt.tight_layout()
plt.show()

"""# Grouping

Although we did simple preprocessing, there are still loops that we couldn't manage to clean. Thus, we use HDBScan to cluster them into groups to identify good and bad loops.
"""

# ============================
# PCA + HDBSCAN on raw loops
# ============================

import hdbscan
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# --------------------------------------------------
# INPUT ASSUMPTION
# --------------------------------------------------
# loops = list of (vdc_raw, y_raw)
# - all loops share the same Vdc grid length
# - vdc_raw, y_raw are 1D numpy arrays of same length
#
# Example:
# loops = [(vdc1, y1), (vdc2, y2), ...]
# --------------------------------------------------


def roll_and_normalize(vdc, y):
    """
    Roll loop so that min(Vdc) is first, then normalize y.
    """
    i0 = np.argmin(vdc)
    y = np.roll(y, -i0)

    # remove offset and scale (shape-only clustering)
    y = y - np.mean(y)
    y = y / (np.std(y) + 1e-12)

    return y


# --------------------------------------------------
# 1) Build raw data matrix from loops
# --------------------------------------------------
Y = []
for y_raw in cleaned_loops: # loops_flat
    Y.append(roll_and_normalize(dc_vec, y_raw))

Y = np.vstack(Y)   # shape: (n_loops, n_points)


# --------------------------------------------------
# 2) PCA (automatic dimensionality selection)
# --------------------------------------------------
pca = PCA(n_components=0.90, svd_solver="full")  # keep 95% variance
Z = pca.fit_transform(Y)

print(f"PCA reduced {Y.shape[1]} → {Z.shape[1]} dimensions")
print(f"Explained variance ratio sum: {pca.explained_variance_ratio_.sum():.3f}")


# --------------------------------------------------
# 3) HDBSCAN clustering (no need to specify K)
# --------------------------------------------------
clusterer = hdbscan.HDBSCAN(
    min_cluster_size=10,   # adjust depending on dataset size
    min_samples=5,
    metric="euclidean"
)

labels = clusterer.fit_predict(Z)


# --------------------------------------------------
# 4) Summary
# --------------------------------------------------
unique_labels, counts = np.unique(labels, return_counts=True)

print("\nCluster summary:")
for lbl, cnt in zip(unique_labels, counts):
    if lbl == -1:
        print(f"  Noise / outliers : {cnt}")
    else:
        print(f"  Cluster {lbl:<2}        : {cnt}")

# labels array corresponds to loops list order
# labels[i] = cluster id for loops[i]

"""## Noise/Outliers

Ones that are too far away from others to be grouped.
"""

num_loops_to_plot = 25
cluster_id = -1  # change to the cluster you want

cluster_idx = np.where(labels == cluster_id)[0]
rand_cluster_idx = np.random.choice(cluster_idx, size=min(25, len(cluster_idx)), replace=False)

# Create a 5x5 grid of subplots
fig, axes = plt.subplots(5, 5, figsize=(15, 15))
axes = axes.flatten() # Flatten the 5x5 array of axes for easier iteration

# Plot each random hysteresis loop in a separate subplot
for i, ax in enumerate(axes):
    if i == len(cluster_idx): break
    loop_index = rand_cluster_idx[i]
    loop_data = cleaned_loops[loop_index]

    ax.plot(vdc_rolled, loop_data)
    ax.set_title(f'Loop {loop_index}')
    ax.set_xlabel('Voltage (V)')
    ax.set_ylabel('Response')
    ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout() # Adjust subplot parameters for a tight layout
plt.show()

"""## Group 5

Complete Hysteresis loops
"""

num_loops_to_plot = 25
cluster_id = 5  # change to the cluster you want

cluster_idx = np.where(labels == cluster_id)[0]
rand_cluster_idx = np.random.choice(cluster_idx, size=min(25, len(cluster_idx)), replace=False)

# Create a 5x5 grid of subplots
fig, axes = plt.subplots(5, 5, figsize=(15, 15))
axes = axes.flatten() # Flatten the 5x5 array of axes for easier iteration

# Plot each random hysteresis loop in a separate subplot
for i, ax in enumerate(axes):
    if i == len(cluster_idx): break
    loop_index = rand_cluster_idx[i]
    loop_data = cleaned_loops[loop_index]

    ax.plot(vdc_rolled, loop_data)
    ax.set_title(f'Loop {loop_index}')
    ax.set_xlabel('Voltage (V)')
    ax.set_ylabel('Response')
    ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout() # Adjust subplot parameters for a tight layout
plt.show()

"""## Group 0

Complete Hysteresis loops but flipped horizontal compared to the majority
"""

num_loops_to_plot = 25
cluster_id = 0  # change to the cluster you want

cluster_idx = np.where(labels == cluster_id)[0]
rand_cluster_idx = np.random.choice(cluster_idx, size=min(25, len(cluster_idx)), replace=False)

# Create a 5x5 grid of subplots
fig, axes = plt.subplots(5, 5, figsize=(15, 15))
axes = axes.flatten() # Flatten the 5x5 array of axes for easier iteration

# Plot each random hysteresis loop in a separate subplot
for i, ax in enumerate(axes):
    if i == len(cluster_idx): break
    loop_index = rand_cluster_idx[i]
    loop_data = cleaned_loops[loop_index]

    ax.plot(vdc_rolled, loop_data)
    ax.set_title(f'Loop {loop_index}')
    ax.set_xlabel('Voltage (V)')
    ax.set_ylabel('Response')
    ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout() # Adjust subplot parameters for a tight layout
plt.show()

"""## Group 1-4

Loops in this group required further cleaning.
"""

num_loops_to_plot = 9
for cluster_id in range(1,5):

  cluster_idx = np.where(labels == cluster_id)[0]
  rand_cluster_idx = np.random.choice(cluster_idx, size=min(9, len(cluster_idx)), replace=False)

  # Create a 5x5 grid of subplots
  fig, axes = plt.subplots(3, 3, figsize=(9, 9))
  axes = axes.flatten() # Flatten the 5x5 array of axes for easier iteration

  # Plot each random hysteresis loop in a separate subplot
  for i, ax in enumerate(axes):
      if i == len(cluster_idx): break
      loop_index = rand_cluster_idx[i]
      loop_data = cleaned_loops[loop_index]

      ax.plot(vdc_rolled, loop_data)
      ax.set_title(f'Loop {loop_index}')
      ax.set_xlabel('Voltage (V)')
      ax.set_ylabel('Response')
      ax.grid(True, linestyle='--', alpha=0.7)

  plt.suptitle(f'Cluster: {cluster_id}')
  plt.tight_layout() # Adjust subplot parameters for a tight layout
  plt.show()

"""## Get labels"""

import pandas as pd

label_df = pd.DataFrame({
    "idx": np.arange(len(labels)),
    "label": labels
})

label_df.set_index('idx', inplace=True)
label_df.head()

"""# Fitting

Mainly Group 0 & Group 5

Main idea:

Initiation has a significant impact on optmization of parameters.
Thus, we use multiple initiation.

We also use different values for d which helps in optimization process.
"""

import numpy as np
from scipy.optimize import least_squares
from scipy.special import erf


# -----------------------------
# Original-order model
# coef_vec = [a0,a1,a2,a3,a4,b0,b1,b2,b3]
# -----------------------------
def loop_model_coef(vdc, coef_vec, d=1000.0):
    coef_vec = np.asarray(coef_vec, float)
    a0,a1,a2,a3,a4,b0,b1,b2,b3 = coef_vec

    vdc = np.asarray(vdc, float)
    n2 = len(vdc) // 2
    v1, v2 = vdc[:n2], vdc[n2:]

    g1 = (b1 - b0) / 2.0 * (erf((v1 - a2) * d) + 1.0) + b0
    g2 = (b3 - b2) / 2.0 * (erf((v2 - a3) * d) + 1.0) + b2

    y1 = (g1 * erf((v1 - a2) / g1) + b0) / (b0 + b1)
    y2 = (g2 * erf((v2 - a3) / g2) + b2) / (b2 + b3)

    f1 = a0 + a1 * y1 + a4 * v1
    f2 = a0 + a1 * y2 + a4 * v2
    return np.hstack([f1, f2])

def residuals_coef(coef_vec, vdc, y_obs, d=1000.0):
    return loop_model_coef(vdc, coef_vec, d=d) - np.asarray(y_obs, float)

# -----------------------------
# Heuristic initialization (coef_vec order)
# -----------------------------
def _switch_center_by_max_slope(v, y):
    v = np.asarray(v, float); y = np.asarray(y, float)
    dy = np.gradient(y, v)
    return float(v[np.argmax(np.abs(dy))])

def _robust_slope_tail(v, y, frac=0.2):
    v = np.asarray(v, float); y = np.asarray(y, float)
    n = len(v); k = max(3, int(frac * n))
    order = np.argsort(v)
    idx = np.r_[order[:k], order[-k:]]
    X = np.column_stack([np.ones(len(idx)), v[idx]])
    beta, *_ = np.linalg.lstsq(X, y[idx], rcond=None)
    return float(beta[1])

def _width_10_90(v, y):
    v = np.asarray(v, float); y = np.asarray(y, float)
    ymin, ymax = float(np.min(y)), float(np.max(y))
    if ymax - ymin < 1e-12:
        return 2.0
    yn = (y - ymin) / (ymax - ymin)
    order = np.argsort(v)
    v2, yn2 = v[order], yn[order]

    def interp_x(level):
        idx = np.where(yn2 >= level)[0]
        if len(idx) == 0:
            return float(v2[-1])
        i = idx[0]
        if i == 0:
            return float(v2[0])
        x0, x1 = v2[i-1], v2[i]
        y0, y1 = yn2[i-1], yn2[i]
        t = 0.0 if abs(y1 - y0) < 1e-12 else (level - y0) / (y1 - y0)
        return float(x0 + t * (x1 - x0))

    return max(0.2, abs(interp_x(0.90) - interp_x(0.10)))

def make_x0_coef(vdc, y_obs):
    vdc = np.asarray(vdc, float)
    y_obs = np.asarray(y_obs, float)
    n2 = len(vdc) // 2
    v1, v2 = vdc[:n2], vdc[n2:]
    y1, y2 = y_obs[:n2], y_obs[n2:]

    a2 = _switch_center_by_max_slope(v1, y1)
    a3 = _switch_center_by_max_slope(v2, y2)
    a4 = _robust_slope_tail(vdc, y_obs, frac=0.2)

    a0 = float(np.median(y_obs))
    a1 = float(np.max(y_obs) - np.min(y_obs))
    if abs(a1) < 1e-12:
        a1 = 1.0

    w1 = _width_10_90(v1, y1)
    w2 = _width_10_90(v2, y2)

    # b's in VOLTS; keep positive and O(0.1–10)
    b0 = max(0.1, 0.5 * w1)
    b1 = max(0.2, 1.2 * w1)
    b2 = max(0.1, 0.5 * w2)
    b3 = max(0.2, 1.2 * w2)

    # coef_vec order:
    return np.array([a0, a1, a2, a3, a4, b0, b1, b2, b3], float)

# -----------------------------
# Strong Option A (multi-start + continuation), returns coef_vec order
# -----------------------------
def fit_optionA_strong_coef(
    vdc, y_obs,
    n_starts=30,
    d_schedule=(40, 120, 400, 1000),
    seed=0,
    b_max=20.0
):
    rng = np.random.default_rng(seed)
    vdc = np.asarray(vdc, float)
    y_obs = np.asarray(y_obs, float)
    vmin, vmax = float(np.min(vdc)), float(np.max(vdc))

    # bounds in coef_vec order: [a0,a1,a2,a3,a4,b0,b1,b2,b3]
    lb = np.array([-np.inf, -np.inf, vmin, vmin, -np.inf, 1e-3, 1e-3, 1e-3, 1e-3], float)
    ub = np.array([ np.inf,  np.inf, vmax, vmax,  np.inf, b_max, b_max, b_max, b_max], float)

    base = make_x0_coef(vdc, y_obs)

    def jitter(coef):
        c = coef.copy()
        # jitter switch centers
        c[2] += rng.normal(0, 0.8)  # a2
        c[3] += rng.normal(0, 0.8)  # a3
        # jitter b's multiplicatively
        for j in [5, 6, 7, 8]:
            c[j] *= np.exp(rng.normal(0, 0.35))
        # jitter linear terms mildly
        c[0] += rng.normal(0, 0.2 * np.std(y_obs))      # a0
        c[1] *= np.exp(rng.normal(0, 0.2))              # a1
        c[4] += rng.normal(0, 0.2 * abs(c[4]) + 1e-6)   # a4
        return c

    best = None
    best_cost = np.inf

    for s in range(n_starts):
        x0 = base if s == 0 else jitter(base)
        x0 = np.minimum(np.maximum(x0, lb), ub)

        x = x0
        for d in d_schedule:
            res = least_squares(
                residuals_coef, x,
                args=(vdc, y_obs, d),
                method="trf",
                loss="soft_l1",
                bounds=(lb, ub),
                x_scale="jac",
                max_nfev=4000
            )
            x = res.x

        if res.cost < best_cost:
            best_cost = res.cost
            best = x

    return best  # <-- this is coef_vec in your original order

cluster_id = 0
cluster_idx = label_df[label_df['label']==cluster_id].index
selected_loop_id = np.random.choice(cluster_idx, size=1, replace=False)[0]

y = cleaned_loops[selected_loop_id]

p_best = fit_optionA_strong_coef(vdc_rolled, y, n_starts=40, d_schedule=(30,80,200,600,1000), seed=1)
y_pred = loop_fit_function(vdc_rolled, p_best)
print("best params:", p_best)

plt.figure(figsize=(6,6))
plt.plot(vdc_rolled, y, label="obs")
plt.plot(vdc_rolled, y_pred, label="pred")
plt.legend(); plt.grid(True); plt.show()

rmse = np.sqrt(np.mean((y_pred - y)**2))
print("RMSE:", rmse)

cluster_id = 5
cluster_idx = label_df[label_df['label']==cluster_id].index
selected_loop_id = np.random.choice(cluster_idx, size=1, replace=False)[0]

y = cleaned_loops[selected_loop_id]

p_best = fit_optionA_strong_coef(vdc_rolled, y, n_starts=40, d_schedule=(30,80,200,600,1000), seed=1)
y_pred = loop_fit_function(vdc_rolled, p_best)
print("best params:", p_best)

plt.figure(figsize=(6,6))
plt.plot(vdc_rolled, y, label="obs")
plt.plot(vdc_rolled, y_pred, label="pred")
plt.legend(); plt.grid(True); plt.show()

rmse = np.sqrt(np.mean((y_pred - y)**2))
print("RMSE:", rmse)

"""# Loop for all

Lower n_starts for faster run.
"""

from tqdm import tqdm

cluster_id = 0
cluster_idx = label_df[label_df['label']==cluster_id].index

rows = []

for selected_loop_id in tqdm(cluster_idx):
  y = cleaned_loops[selected_loop_id]

  p_best = fit_optionA_strong_coef(vdc_rolled, y, n_starts=8, d_schedule=(30,80,200,600,1000), seed=1)
  y_pred = loop_fit_function(vdc_rolled, p_best)

  rmse = np.sqrt(np.mean((y_pred - y)**2))
  row = {
      'loop_id':selected_loop_id, 'rmse':rmse,
      'a0': p_best[0],
      'a1': p_best[1],
      'a2': p_best[2],
      'a3': p_best[3],
      'a4': p_best[4],
      'b0': p_best[5],
      'b1': p_best[6],
      'b2': p_best[7],
      'b3': p_best[8],
  }
  rows.append(row)

result_cluster0 = pd.DataFrame(rows)
result_cluster0

cluster_id = 5
cluster_idx = label_df[label_df['label']==cluster_id].index

rows = []

for selected_loop_id in tqdm(cluster_idx):
  y = cleaned_loops[selected_loop_id]

  p_best = fit_optionA_strong_coef(vdc_rolled, y, n_starts=8, d_schedule=(30,80,200,600,1000), seed=1)
  y_pred = loop_fit_function(vdc_rolled, p_best)

  rmse = np.sqrt(np.mean((y_pred - y)**2))
  row = {
      'loop_id':selected_loop_id, 'rmse':rmse,
      'a0': p_best[0],
      'a1': p_best[1],
      'a2': p_best[2],
      'a3': p_best[3],
      'a4': p_best[4],
      'b0': p_best[5],
      'b1': p_best[6],
      'b2': p_best[7],
      'b3': p_best[8],
  }
  rows.append(row)

result_cluster5 = pd.DataFrame(rows)
result_cluster5

result_cluster0['rmse'].hist()
print(result_cluster0['rmse'].mean())
plt.show()
result_cluster5['rmse'].hist()
print(result_cluster5['rmse'].mean())
plt.show()

result_cluster0.to_csv('result_cluster0.csv')
result_cluster5.to_csv('result_cluster5.csv')

result_cluster0 = None
result_cluster5 = None

rows = []

for selected_loop_id in tqdm(range(len(cleaned_loops))):
  y = cleaned_loops[selected_loop_id]

  p_best = fit_optionA_strong_coef(vdc_rolled, y, n_starts=8, d_schedule=(30,80,200,600,1000), seed=1)
  y_pred = loop_fit_function(vdc_rolled, p_best)

  rmse = np.sqrt(np.mean((y_pred - y)**2))
  row = {
      'loop_id':selected_loop_id, 'rmse':rmse,
      'a0': p_best[0],
      'a1': p_best[1],
      'a2': p_best[2],
      'a3': p_best[3],
      'a4': p_best[4],
      'b0': p_best[5],
      'b1': p_best[6],
      'b2': p_best[7],
      'b3': p_best[8],
  }
  rows.append(row)

result = pd.DataFrame(rows)
result.to_csv('result.csv')
result

